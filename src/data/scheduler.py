"""
æ•°æ®é‡‡é›†å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨

æ”¯æŒåŸºäºcronè¡¨è¾¾å¼çš„å®šæ—¶æ•°æ®é‡‡é›†ï¼Œä»¥åŠç¨‹åºå¯åŠ¨æ—¶çš„ç«‹å³é‡‡é›†
"""

import os
import asyncio
import logging
from typing import Optional, Dict, Any
from datetime import datetime
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger
from apscheduler.executors.asyncio import AsyncIOExecutor

from .storage_manager import storage_manager

logger = logging.getLogger(__name__)


class DataCollectionScheduler:
    """æ•°æ®é‡‡é›†è°ƒåº¦å™¨"""
    
    def __init__(self):
        self.scheduler: Optional[AsyncIOScheduler] = None
        self.client = None
        self._running = False
        
    def initialize(self, client) -> None:
        """
        åˆå§‹åŒ–è°ƒåº¦å™¨
        
        Args:
            client: å°çº¢ä¹¦å®¢æˆ·ç«¯å®ä¾‹
        """
        self.client = client
        
        # åˆ›å»ºè°ƒåº¦å™¨
        executors = {
            'default': AsyncIOExecutor()
        }
        
        job_defaults = {
            'coalesce': False,
            'max_instances': 1
        }
        
        timezone = os.getenv('TIMEZONE', 'Asia/Shanghai')
        
        self.scheduler = AsyncIOScheduler(
            executors=executors,
            job_defaults=job_defaults,
            timezone=timezone
        )
        
        logger.info(f"æ•°æ®é‡‡é›†è°ƒåº¦å™¨å·²åˆå§‹åŒ–ï¼Œæ—¶åŒº: {timezone}")
        
    async def start(self) -> None:
        """å¯åŠ¨è°ƒåº¦å™¨"""
        if not self.scheduler:
            logger.error("è°ƒåº¦å™¨æœªåˆå§‹åŒ–")
            return
            
        if self._running:
            logger.warning("è°ƒåº¦å™¨å·²åœ¨è¿è¡Œä¸­")
            return
            
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨è‡ªåŠ¨é‡‡é›†
        enable_auto_collection = os.getenv('ENABLE_AUTO_COLLECTION', 'true').lower() == 'true'
        
        if not enable_auto_collection:
            logger.info("è‡ªåŠ¨æ•°æ®é‡‡é›†å·²ç¦ç”¨")
            return
            
        # å¯åŠ¨è°ƒåº¦å™¨
        self.scheduler.start()
        self._running = True
        logger.info("æ•°æ®é‡‡é›†è°ƒåº¦å™¨å·²å¯åŠ¨")
        
        # æ·»åŠ å®šæ—¶ä»»åŠ¡
        self._add_scheduled_jobs()
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦åœ¨å¯åŠ¨æ—¶ç«‹å³æ‰§è¡Œä¸€æ¬¡é‡‡é›†
        run_on_startup = os.getenv('RUN_ON_STARTUP', 'true').lower() == 'true'
        
        if run_on_startup:
            logger.info("ç¨‹åºå¯åŠ¨æ—¶æ‰§è¡Œæ•°æ®é‡‡é›†...")
            await self._run_data_collection()
            
    def _add_scheduled_jobs(self) -> None:
        """æ·»åŠ å®šæ—¶ä»»åŠ¡"""
        # è·å–cronè¡¨è¾¾å¼
        cron_schedule = os.getenv('COLLECTION_SCHEDULE', '0 1 * * *')
        
        try:
            # è§£æcronè¡¨è¾¾å¼
            cron_parts = cron_schedule.split()
            
            if len(cron_parts) == 5:
                # æ ‡å‡†cronæ ¼å¼ï¼šåˆ† æ—¶ æ—¥ æœˆ æ˜ŸæœŸ
                minute, hour, day, month, day_of_week = cron_parts
                second = '0'
            elif len(cron_parts) == 6:
                # æ‰©å±•cronæ ¼å¼ï¼šç§’ åˆ† æ—¶ æ—¥ æœˆ æ˜ŸæœŸ
                second, minute, hour, day, month, day_of_week = cron_parts
            else:
                raise ValueError(f"æ— æ•ˆçš„cronè¡¨è¾¾å¼æ ¼å¼: {cron_schedule}")
                
            # åˆ›å»ºcronè§¦å‘å™¨
            trigger = CronTrigger(
                second=second,
                minute=minute,
                hour=hour,
                day=day,
                month=month,
                day_of_week=day_of_week
            )
            
            # æ·»åŠ å®šæ—¶ä»»åŠ¡
            self.scheduler.add_job(
                func=self._run_data_collection,
                trigger=trigger,
                id='data_collection_job',
                name='æ•°æ®é‡‡é›†ä»»åŠ¡',
                replace_existing=True
            )
            
            logger.info(f"å®šæ—¶æ•°æ®é‡‡é›†ä»»åŠ¡å·²æ·»åŠ ï¼Œè®¡åˆ’: {cron_schedule}")
            
        except Exception as e:
            logger.error(f"æ·»åŠ å®šæ—¶ä»»åŠ¡å¤±è´¥: {e}")
            
    async def _run_data_collection(self) -> None:
        """æ‰§è¡Œæ•°æ®é‡‡é›†"""
        if not self.client:
            logger.error("å®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œæ— æ³•æ‰§è¡Œæ•°æ®é‡‡é›†")
            return
            
        logger.info("å¼€å§‹æ‰§è¡Œæ•°æ®é‡‡é›†ä»»åŠ¡...")
        start_time = datetime.now()
        
        # è·å–é‡‡é›†é…ç½®
        collect_dashboard = os.getenv('COLLECT_DASHBOARD', 'true').lower() == 'true'
        collect_content = os.getenv('COLLECT_CONTENT_ANALYSIS', 'true').lower() == 'true'
        collect_fans = os.getenv('COLLECT_FANS', 'true').lower() == 'true'
        
        success_count = 0
        total_count = 0
        
        # åŠ¨æ€å¯¼å…¥æ•°æ®é‡‡é›†æ¨¡å—ï¼ˆé¿å…å¾ªç¯å¯¼å…¥ï¼‰
        try:
            from ..xiaohongshu.data_collector.dashboard import collect_dashboard_data
            from ..xiaohongshu.data_collector.content_analysis import collect_content_analysis_data
            from ..xiaohongshu.data_collector.fans import collect_fans_data
        except ImportError as e:
            logger.error(f"å¯¼å…¥æ•°æ®é‡‡é›†æ¨¡å—å¤±è´¥: {e}")
            # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œå°è¯•å¦ä¸€ç§å¯¼å…¥æ–¹å¼
            try:
                import sys
                sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))
                from xiaohongshu.data_collector.dashboard import collect_dashboard_data
                from xiaohongshu.data_collector.content_analysis import collect_content_analysis_data
                from xiaohongshu.data_collector.fans import collect_fans_data
                logger.info("ä½¿ç”¨å¤‡ç”¨å¯¼å…¥æ–¹å¼æˆåŠŸ")
            except ImportError as e2:
                logger.error(f"å¤‡ç”¨å¯¼å…¥æ–¹å¼ä¹Ÿå¤±è´¥: {e2}")
                return
        
        # åˆ›å»ºWebDriverå®ä¾‹ç”¨äºæ•°æ®é‡‡é›†
        driver = None
        try:
            driver = self.client.browser_manager.create_driver()
            
            # åŠ è½½cookies
            cookies = self.client.cookie_manager.load_cookies()
            if cookies:
                # å…ˆè®¿é—®å°çº¢ä¹¦ä¸»é¡µä»¥è®¾ç½®åŸŸå
                driver.get("https://www.xiaohongshu.com")
                
                # åŠ è½½cookies
                cookie_result = self.client.browser_manager.load_cookies(cookies)
                logger.info(f"ğŸª CookiesåŠ è½½ç»“æœ: {cookie_result}")
            else:
                logger.warning("âš ï¸ æœªæ‰¾åˆ°cookiesï¼Œæ•°æ®é‡‡é›†å¯èƒ½å¤±è´¥")
        
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºWebDriverå¤±è´¥: {e}")
            return
        
        try:
            # é‡‡é›†ä»ªè¡¨æ¿æ•°æ®
            if collect_dashboard:
                total_count += 1
                try:
                    logger.info("é‡‡é›†ä»ªè¡¨æ¿æ•°æ®...")
                    result = collect_dashboard_data(driver, save_data=True)
                    if result.get("success", False):
                        success_count += 1
                        logger.info("âœ… ä»ªè¡¨æ¿æ•°æ®é‡‡é›†å®Œæˆ")
                    else:
                        logger.error(f"âŒ ä»ªè¡¨æ¿æ•°æ®é‡‡é›†å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                except Exception as e:
                    logger.error(f"âŒ ä»ªè¡¨æ¿æ•°æ®é‡‡é›†å¤±è´¥: {e}")
                    
            # é‡‡é›†å†…å®¹åˆ†ææ•°æ®
            if collect_content:
                total_count += 1
                try:
                    logger.info("é‡‡é›†å†…å®¹åˆ†ææ•°æ®...")
                    result = await collect_content_analysis_data(driver, save_data=True)
                    if result.get("success", False):
                        success_count += 1
                        logger.info("âœ… å†…å®¹åˆ†ææ•°æ®é‡‡é›†å®Œæˆ")
                    else:
                        logger.error(f"âŒ å†…å®¹åˆ†ææ•°æ®é‡‡é›†å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                except Exception as e:
                    logger.error(f"âŒ å†…å®¹åˆ†ææ•°æ®é‡‡é›†å¤±è´¥: {e}")
                    
            # é‡‡é›†ç²‰ä¸æ•°æ®
            if collect_fans:
                total_count += 1
                try:
                    logger.info("é‡‡é›†ç²‰ä¸æ•°æ®...")
                    result = collect_fans_data(driver, save_data=True)
                    if result.get("success", False):
                        success_count += 1
                        logger.info("âœ… ç²‰ä¸æ•°æ®é‡‡é›†å®Œæˆ")
                    else:
                        logger.error(f"âŒ ç²‰ä¸æ•°æ®é‡‡é›†å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                except Exception as e:
                    logger.error(f"âŒ ç²‰ä¸æ•°æ®é‡‡é›†å¤±è´¥: {e}")
                    
        finally:
            # ç¡®ä¿å…³é—­WebDriver
            if driver:
                try:
                    driver.quit()
                    logger.debug("ğŸ”’ WebDriverå·²å…³é—­")
                except Exception as e:
                    logger.warning(f"âš ï¸ å…³é—­WebDriveræ—¶å‡ºé”™: {e}")
                
        # è®°å½•é‡‡é›†ç»“æœ
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        logger.info(f"æ•°æ®é‡‡é›†ä»»åŠ¡å®Œæˆï¼ŒæˆåŠŸ: {success_count}/{total_count}ï¼Œè€—æ—¶: {duration:.2f}ç§’")
        
        # ä¿å­˜é‡‡é›†æ—¥å¿—åˆ°å­˜å‚¨
        collection_log = {
            'timestamp': start_time.isoformat(),
            'duration_seconds': duration,
            'total_tasks': total_count,
            'successful_tasks': success_count,
            'failed_tasks': total_count - success_count,
            'tasks': {
                'dashboard': collect_dashboard,
                'content_analysis': collect_content,
                'fans': collect_fans
            }
        }
        
        try:
            # è¿™é‡Œå¯ä»¥å°†é‡‡é›†æ—¥å¿—ä¿å­˜åˆ°å•ç‹¬çš„æ—¥å¿—è¡¨æˆ–æ–‡ä»¶
            logger.debug(f"é‡‡é›†æ—¥å¿—: {collection_log}")
        except Exception as e:
            logger.error(f"ä¿å­˜é‡‡é›†æ—¥å¿—å¤±è´¥: {e}")
            
    async def stop(self) -> None:
        """åœæ­¢è°ƒåº¦å™¨"""
        if self.scheduler and self._running:
            self.scheduler.shutdown(wait=True)
            self._running = False
            logger.info("æ•°æ®é‡‡é›†è°ƒåº¦å™¨å·²åœæ­¢")
            
    def is_running(self) -> bool:
        """æ£€æŸ¥è°ƒåº¦å™¨æ˜¯å¦åœ¨è¿è¡Œ"""
        return self._running
        
    def get_job_info(self) -> Dict[str, Any]:
        """è·å–ä»»åŠ¡ä¿¡æ¯"""
        if not self.scheduler:
            return {'status': 'not_initialized'}
            
        jobs = []
        for job in self.scheduler.get_jobs():
            jobs.append({
                'id': job.id,
                'name': job.name,
                'next_run_time': job.next_run_time.isoformat() if job.next_run_time else None,
                'trigger': str(job.trigger)
            })
            
        return {
            'status': 'running' if self._running else 'stopped',
            'jobs': jobs,
            'config': {
                'enable_auto_collection': os.getenv('ENABLE_AUTO_COLLECTION', 'true'),
                'run_on_startup': os.getenv('RUN_ON_STARTUP', 'true'),
                'collection_schedule': os.getenv('COLLECTION_SCHEDULE', '0 1 * * *'),
                'timezone': os.getenv('TIMEZONE', 'Asia/Shanghai'),
                'collect_dashboard': os.getenv('COLLECT_DASHBOARD', 'true'),
                'collect_content_analysis': os.getenv('COLLECT_CONTENT_ANALYSIS', 'true'),
                'collect_fans': os.getenv('COLLECT_FANS', 'true')
            }
        }
        
    async def run_manual_collection(self) -> Dict[str, Any]:
        """æ‰‹åŠ¨æ‰§è¡Œä¸€æ¬¡æ•°æ®é‡‡é›†"""
        logger.info("æ‰‹åŠ¨è§¦å‘æ•°æ®é‡‡é›†...")
        await self._run_data_collection()
        return {'status': 'completed', 'timestamp': datetime.now().isoformat()}


# å…¨å±€è°ƒåº¦å™¨å®ä¾‹
data_scheduler = DataCollectionScheduler() 