"""
å°çº¢ä¹¦å·¥å…·åŒ…æ–‡æœ¬å¤„ç†å·¥å…·æ¨¡å—

æä¾›æ–‡æœ¬æ¸…ç†ã€æ ¼å¼åŒ–ç­‰å·¥å…·å‡½æ•°
"""

import re
from typing import List, Optional


def clean_text_for_browser(text: str) -> str:
    """
    æ¸…ç†æ–‡æœ¬ä¸­ChromeDriverä¸æ”¯æŒçš„å­—ç¬¦
    
    ChromeDriveråªæ”¯æŒBMP(Basic Multilingual Plane)å­—ç¬¦
    
    Args:
        text: åŸå§‹æ–‡æœ¬
        
    Returns:
        æ¸…ç†åçš„æ–‡æœ¬
    """
    if not text:
        return ""
        
    # ç§»é™¤è¶…å‡ºBMPèŒƒå›´çš„å­—ç¬¦ï¼ˆU+10000åŠä»¥ä¸Šï¼‰
    cleaned_text = ""
    for char in text:
        # BMPå­—ç¬¦èŒƒå›´æ˜¯U+0000åˆ°U+FFFF
        if ord(char) <= 0xFFFF:
            cleaned_text += char
        else:
            # ç”¨ç©ºæ ¼æ›¿æ¢ä¸æ”¯æŒçš„å­—ç¬¦
            cleaned_text += " "
    
    # æ¸…ç†è¿ç»­çš„ç©ºæ ¼ï¼Œä½†ä¿ç•™æ¢è¡Œç¬¦
    # ä½¿ç”¨ [^\S\n]+ åŒ¹é…é™¤æ¢è¡Œç¬¦å¤–çš„æ‰€æœ‰ç©ºç™½å­—ç¬¦
    cleaned_text = re.sub(r'[^\S\n]+', ' ', cleaned_text).strip()
    
    return cleaned_text


def truncate_text(text: str, max_length: int, suffix: str = "...") -> str:
    """
    æˆªæ–­æ–‡æœ¬åˆ°æŒ‡å®šé•¿åº¦
    
    Args:
        text: åŸå§‹æ–‡æœ¬
        max_length: æœ€å¤§é•¿åº¦
        suffix: æˆªæ–­åç¼€
        
    Returns:
        æˆªæ–­åçš„æ–‡æœ¬
    """
    if not text or len(text) <= max_length:
        return text
    
    # ç¡®ä¿åç¼€ä¸ä¼šè¶…è¿‡æœ€å¤§é•¿åº¦
    if len(suffix) >= max_length:
        return text[:max_length]
    
    return text[:max_length - len(suffix)] + suffix


def parse_topics_string(topics_string: str) -> List[str]:
    """
    è§£æè¯é¢˜å­—ç¬¦ä¸²
    
    Args:
        topics_string: è¯é¢˜å­—ç¬¦ä¸²ï¼Œç”¨é€—å·åˆ†éš”
        
    Returns:
        è¯é¢˜åˆ—è¡¨
    """
    if not topics_string:
        return []
    
    # åˆ†å‰²å¹¶æ¸…ç†è¯é¢˜
    topics = [topic.strip() for topic in topics_string.split(",") if topic.strip()]
    
    # ç§»é™¤é‡å¤è¯é¢˜ï¼ˆä¿æŒé¡ºåºï¼‰
    unique_topics = []
    seen = set()
    for topic in topics:
        if topic not in seen:
            unique_topics.append(topic)
            seen.add(topic)
    
    return unique_topics


# ä¸ºäº†å‘åå…¼å®¹ï¼Œä¿ç•™åŸå‡½æ•°å
def parse_tags_string(tags_string: str) -> List[str]:
    """
    è§£ææ ‡ç­¾å­—ç¬¦ä¸²ï¼ˆå·²åºŸå¼ƒï¼Œè¯·ä½¿ç”¨parse_topics_stringï¼‰
    
    Args:
        tags_string: æ ‡ç­¾å­—ç¬¦ä¸²ï¼Œç”¨é€—å·åˆ†éš”
        
    Returns:
        æ ‡ç­¾åˆ—è¡¨
    """
    return parse_topics_string(tags_string)


def parse_file_paths_string(paths_string: str) -> List[str]:
    """
    è§£ææ–‡ä»¶è·¯å¾„å­—ç¬¦ä¸²
    
    Args:
        paths_string: æ–‡ä»¶è·¯å¾„å­—ç¬¦ä¸²ï¼Œç”¨é€—å·åˆ†éš”
        
    Returns:
        æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    if not paths_string:
        return []
    
    # åˆ†å‰²å¹¶æ¸…ç†è·¯å¾„
    paths = [path.strip() for path in paths_string.split(",") if path.strip()]
    
    return paths


def smart_parse_file_paths(paths_input) -> List[str]:
    """
    æ™ºèƒ½è§£ææ–‡ä»¶è·¯å¾„ï¼Œæ”¯æŒå¤šç§è¾“å…¥æ ¼å¼
    
    æ”¯æŒçš„æ ¼å¼ï¼š
    1. é€—å·åˆ†éš”å­—ç¬¦ä¸²ï¼š"a,b,c,d"
    2. æ•°ç»„å­—ç¬¦ä¸²ï¼š"[a,b,c]"
    3. JSONæ•°ç»„å­—ç¬¦ä¸²ï¼š'["a","b","c"]'
    4. çœŸæ­£çš„æ•°ç»„ï¼š["a","b","c"]
    5. å…¶ä»–å¯è¿­ä»£å¯¹è±¡
    
    Args:
        paths_input: å„ç§æ ¼å¼çš„è·¯å¾„è¾“å…¥
        
    Returns:
        æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    import json
    import ast
    
    if not paths_input:
        return []
    
    # æƒ…å†µ1: å¦‚æœè¾“å…¥å·²ç»æ˜¯åˆ—è¡¨æˆ–å…¶ä»–å¯è¿­ä»£å¯¹è±¡ï¼ˆä½†ä¸æ˜¯å­—ç¬¦ä¸²ï¼‰
    if isinstance(paths_input, (list, tuple)):
        # å¤„ç†æ•°ç»„ä¸­çš„æ¯ä¸ªå…ƒç´ ï¼Œç¡®ä¿éƒ½æ˜¯å­—ç¬¦ä¸²
        result = []
        for item in paths_input:
            if isinstance(item, str):
                result.append(item.strip())
            else:
                # å¦‚æœä¸æ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è½¬æ¢ä¸ºå­—ç¬¦ä¸²
                result.append(str(item).strip())
        return [path for path in result if path]  # è¿‡æ»¤ç©ºå­—ç¬¦ä¸²
    
    # æƒ…å†µ2: å¦‚æœè¾“å…¥æ˜¯å­—ç¬¦ä¸²
    if isinstance(paths_input, str):
        paths_str = paths_input.strip()
        
        if not paths_str:
            return []
        
        # 2.1: å°è¯•è§£æJSONæ•°ç»„æ ¼å¼ï¼š'["a","b","c"]'
        if paths_str.startswith('[') and paths_str.endswith(']'):
            try:
                # å…ˆå°è¯•JSONè§£æ
                parsed = json.loads(paths_str)
                if isinstance(parsed, list):
                    return [str(item).strip() for item in parsed if str(item).strip()]
            except json.JSONDecodeError:
                # JSONè§£æå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ast.literal_eval
                try:
                    parsed = ast.literal_eval(paths_str)
                    if isinstance(parsed, (list, tuple)):
                        return [str(item).strip() for item in parsed if str(item).strip()]
                except (ValueError, SyntaxError):
                    # å¦‚æœéƒ½è§£æå¤±è´¥ï¼Œå¯èƒ½æ˜¯æ ¼å¼ä¸æ ‡å‡†çš„æ•°ç»„å­—ç¬¦ä¸²
                    # å°è¯•æ‰‹åŠ¨è§£æï¼š[a,b,c] è¿™ç§æ ¼å¼
                    try:
                        # å»æ‰æ–¹æ‹¬å·
                        inner_content = paths_str[1:-1].strip()
                        if inner_content:
                            # æŒ‰é€—å·åˆ†å‰²
                            items = [item.strip().strip('"\'') for item in inner_content.split(',')]
                            return [item for item in items if item]
                        else:
                            return []
                    except:
                        pass
        
        # 2.2: å°è¯•JSONæ•°ç»„æ ¼å¼ä½†æ²¡æœ‰å¤–å±‚å¼•å·ï¼š["a","b","c"]
        try:
            # ç›´æ¥å°è¯•JSONè§£æ
            parsed = json.loads(paths_str)
            if isinstance(parsed, list):
                return [str(item).strip() for item in parsed if str(item).strip()]
        except json.JSONDecodeError:
            pass
        
        # 2.3: æ™®é€šé€—å·åˆ†éš”æ ¼å¼ï¼š"a,b,c,d"
        if ',' in paths_str:
            paths = [path.strip().strip('"\'') for path in paths_str.split(',')]
            return [path for path in paths if path]
        
        # 2.4: å•ä¸ªæ–‡ä»¶è·¯å¾„
        return [paths_str.strip().strip('"\'')]
    
    # æƒ…å†µ3: å…¶ä»–ç±»å‹ï¼Œå°è¯•è½¬æ¢ä¸ºå­—ç¬¦ä¸²åé€’å½’å¤„ç†
    try:
        return smart_parse_file_paths(str(paths_input))
    except:
        return []


def validate_note_content(title: str, content: str) -> List[str]:
    """
    éªŒè¯ç¬”è®°å†…å®¹
    
    Args:
        title: ç¬”è®°æ ‡é¢˜
        content: ç¬”è®°å†…å®¹
        
    Returns:
        éªŒè¯é”™è¯¯åˆ—è¡¨ï¼Œç©ºåˆ—è¡¨è¡¨ç¤ºéªŒè¯é€šè¿‡
    """
    errors = []
    
    # æ£€æŸ¥æ ‡é¢˜
    if not title or not title.strip():
        errors.append("æ ‡é¢˜ä¸èƒ½ä¸ºç©º")
    elif len(title.strip()) > 50:
        errors.append("æ ‡é¢˜é•¿åº¦ä¸èƒ½è¶…è¿‡50ä¸ªå­—ç¬¦")
    
    # æ£€æŸ¥å†…å®¹
    if not content or not content.strip():
        errors.append("å†…å®¹ä¸èƒ½ä¸ºç©º")
    elif len(content.strip()) > 1000:
        errors.append("å†…å®¹é•¿åº¦ä¸èƒ½è¶…è¿‡1000ä¸ªå­—ç¬¦")
    
    return errors


def safe_print(text: str) -> None:
    """
    å®‰å…¨æ‰“å°å‡½æ•°ï¼Œå¤„ç†Windowsä¸‹çš„Unicodeç¼–ç é—®é¢˜
    
    Args:
        text: è¦æ‰“å°çš„æ–‡æœ¬
    """
    try:
        print(text)
    except UnicodeEncodeError:
        # æ›¿æ¢å¸¸è§çš„emojiå­—ç¬¦ä¸ºæ–‡æœ¬
        replacements = {
            'ğŸ”§': '[é…ç½®]',
            'âœ…': '[æˆåŠŸ]',  
            'âŒ': '[å¤±è´¥]',
            'âš ï¸': '[è­¦å‘Š]',
            'ğŸª': '[Cookie]',
            'ğŸš€': '[å¯åŠ¨]',
            'ğŸ›‘': '[åœæ­¢]',
            'ğŸ”': '[æ£€æŸ¥]',
            'ğŸ“': '[ç¬”è®°]',
            'ğŸ“Š': '[çŠ¶æ€]',
            'ğŸ’»': '[ç³»ç»Ÿ]',
            'ğŸ': '[Python]',
            'ğŸ’¡': '[æç¤º]',
            'ğŸ“„': '[æ–‡ä»¶]',
            'ğŸ§ª': '[æµ‹è¯•]',
            'ğŸ“±': '[å‘å¸ƒ]',
            'ğŸ‰': '[å®Œæˆ]',
            'ğŸŒº': '[å°çº¢ä¹¦]',
            'ğŸ§¹': '[æ¸…ç†]',
            'ğŸ‘‹': '[å†è§]',
            'ğŸ“¡': '[ä¿¡å·]'
        }
        
        safe_text = text
        for emoji, replacement in replacements.items():
            safe_text = safe_text.replace(emoji, replacement)
        
        print(safe_text) 