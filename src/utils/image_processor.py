"""
å›¾ç‰‡å¤„ç†æ¨¡å—

æ”¯æŒå¤šç§å›¾ç‰‡è¾“å…¥æ ¼å¼çš„å¤„ç†ï¼š
- æœ¬åœ°æ–‡ä»¶è·¯å¾„
- ç½‘ç»œURL
"""

import os
import asyncio
import aiohttp
import tempfile
from pathlib import Path
from typing import List, Union, Optional
import uuid

from .logger import get_logger

logger = get_logger(__name__)


class ImageProcessor:
    """å›¾ç‰‡å¤„ç†å™¨ï¼Œæ”¯æŒæœ¬åœ°è·¯å¾„å’ŒURLä¸‹è½½"""
    
    def __init__(self, temp_dir: str = None):
        """
        åˆå§‹åŒ–å›¾ç‰‡å¤„ç†å™¨
        
        Args:
            temp_dir: ä¸´æ—¶æ–‡ä»¶ç›®å½•è·¯å¾„
        """
        # è®¾ç½®ä¸´æ—¶ç›®å½•
        if temp_dir:
            self.temp_dir = Path(temp_dir)
        else:
            # ä½¿ç”¨ç³»ç»Ÿä¸´æ—¶ç›®å½•
            self.temp_dir = Path(tempfile.gettempdir()) / "xhs_images"
        
        self.temp_dir.mkdir(exist_ok=True, parents=True)
        logger.info(f"å›¾ç‰‡å¤„ç†å™¨åˆå§‹åŒ–ï¼Œä¸´æ—¶ç›®å½•: {self.temp_dir}")
    
    async def process_images(self, images_input: Union[str, List, None]) -> List[str]:
        """
        å¤„ç†å„ç§æ ¼å¼çš„å›¾ç‰‡è¾“å…¥ï¼Œè¿”å›æœ¬åœ°æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        
        æ”¯æŒæ ¼å¼ï¼š
        - æœ¬åœ°è·¯å¾„: "/path/to/image.jpg"
        - ç½‘ç»œåœ°å€: "https://example.com/image.jpg"
        - æ··åˆåˆ—è¡¨: ["path.jpg", "https://..."]
        
        Args:
            images_input: å›¾ç‰‡è¾“å…¥ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
            
        Returns:
            List[str]: æœ¬åœ°æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        if not images_input:
            return []
        
        # ç»Ÿä¸€è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼
        images_list = self._normalize_to_list(images_input)
        
        # å¤„ç†æ¯ä¸ªå›¾ç‰‡
        local_paths = []
        for idx, img in enumerate(images_list):
            try:
                local_path = await self._process_single_image(img, idx)
                if local_path:
                    local_paths.append(local_path)
                    logger.info(f"âœ… å¤„ç†å›¾ç‰‡æˆåŠŸ [{idx+1}/{len(images_list)}]: {local_path}")
            except Exception as e:
                logger.error(f"âŒ å¤„ç†å›¾ç‰‡å¤±è´¥ [{idx+1}/{len(images_list)}]: {e}")
                continue
        
        logger.info(f"ğŸ“¸ å›¾ç‰‡å¤„ç†å®Œæˆï¼Œå…±å¤„ç† {len(local_paths)}/{len(images_list)} å¼ ")
        return local_paths
    
    def _normalize_to_list(self, images_input: Union[str, List]) -> List:
        """å°†å„ç§è¾“å…¥æ ¼å¼ç»Ÿä¸€è½¬æ¢ä¸ºåˆ—è¡¨"""
        if isinstance(images_input, str):
            # å•ä¸ªå­—ç¬¦ä¸²ï¼Œå¯èƒ½æ˜¯è·¯å¾„æˆ–é€—å·åˆ†éš”çš„å¤šä¸ªè·¯å¾„
            if ',' in images_input:
                # é€—å·åˆ†éš”çš„å¤šä¸ªè·¯å¾„
                return [img.strip() for img in images_input.split(',') if img.strip()]
            else:
                return [images_input]
        elif isinstance(images_input, list):
            return images_input
        else:
            # å…¶ä»–ç±»å‹ï¼Œè¿”å›ç©ºåˆ—è¡¨
            logger.warning(f"âš ï¸ ä¸æ”¯æŒçš„è¾“å…¥ç±»å‹: {type(images_input)}")
            return []
    
    async def _process_single_image(self, img_input: str, index: int) -> Optional[str]:
        """
        å¤„ç†å•ä¸ªå›¾ç‰‡è¾“å…¥
        
        Args:
            img_input: å›¾ç‰‡è¾“å…¥ï¼ˆå­—ç¬¦ä¸²ï¼‰
            index: å›¾ç‰‡ç´¢å¼•
            
        Returns:
            Optional[str]: æœ¬åœ°æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥è¿”å›None
        """
        if not isinstance(img_input, str):
            logger.warning(f"âš ï¸ æ— æ•ˆçš„å›¾ç‰‡è¾“å…¥ç±»å‹: {type(img_input)}")
            return None
            
        # æ£€æŸ¥æ˜¯å¦æ˜¯ç½‘ç»œåœ°å€
        if img_input.startswith(('http://', 'https://')):
            # ç½‘ç»œåœ°å€
            return await self._download_from_url(img_input, index)
        elif os.path.exists(img_input):
            # æœ¬åœ°æ–‡ä»¶
            return os.path.abspath(img_input)
        else:
            logger.warning(f"âš ï¸ æ— æ•ˆçš„å›¾ç‰‡è·¯å¾„: {img_input}")
            return None
    
    async def _download_from_url(self, url: str, index: int) -> Optional[str]:
        """
        ä¸‹è½½ç½‘ç»œå›¾ç‰‡åˆ°æœ¬åœ°
        
        Args:
            url: å›¾ç‰‡URL
            index: å›¾ç‰‡ç´¢å¼•
            
        Returns:
            Optional[str]: æœ¬åœ°æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            logger.info(f"â¬‡ï¸ å¼€å§‹ä¸‹è½½å›¾ç‰‡: {url}")
            
            async with aiohttp.ClientSession() as session:
                async with session.get(url, timeout=aiohttp.ClientTimeout(total=30)) as response:
                    if response.status != 200:
                        logger.error(f"âŒ ä¸‹è½½å›¾ç‰‡å¤±è´¥: {url}, çŠ¶æ€ç : {response.status}")
                        return None
                    
                    # è·å–æ–‡ä»¶æ‰©å±•å
                    content_type = response.headers.get('content-type', '')
                    ext = self._get_extension_from_content_type(content_type)
                    if not ext:
                        # ä»URLä¸­å°è¯•è·å–æ‰©å±•å
                        url_path = Path(url.split('?')[0])
                        ext = url_path.suffix or '.jpg'
                    
                    # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
                    filename = f"download_{index}_{uuid.uuid4().hex[:8]}{ext}"
                    filepath = self.temp_dir / filename
                    
                    # ä¿å­˜æ–‡ä»¶
                    content = await response.read()
                    filepath.write_bytes(content)
                    
                    logger.info(f"âœ… ä¸‹è½½å›¾ç‰‡æˆåŠŸ: {url} -> {filepath}")
                    return str(filepath)
                    
        except asyncio.TimeoutError:
            raise Exception(f"ä¸‹è½½å›¾ç‰‡è¶…æ—¶: {url}")
        except Exception as e:
            raise Exception(f"ä¸‹è½½å›¾ç‰‡å¤±è´¥: {url}, é”™è¯¯: {str(e)}")
    
    def _get_extension_from_content_type(self, content_type: str) -> str:
        """æ ¹æ®content-typeè·å–æ–‡ä»¶æ‰©å±•å"""
        mapping = {
            'image/jpeg': '.jpg',
            'image/jpg': '.jpg',
            'image/png': '.png',
            'image/gif': '.gif',
            'image/webp': '.webp'
        }
        
        # æå–ä¸»è¦çš„å†…å®¹ç±»å‹ï¼ˆå»é™¤å‚æ•°ï¼‰
        main_type = content_type.split(';')[0].strip().lower()
        return mapping.get(main_type, '')
    
    def cleanup_old_files(self, max_age_hours: int = 24):
        """
        æ¸…ç†è¶…è¿‡æŒ‡å®šæ—¶é—´çš„ä¸´æ—¶æ–‡ä»¶
        
        Args:
            max_age_hours: æ–‡ä»¶æœ€å¤§ä¿ç•™æ—¶é—´ï¼ˆå°æ—¶ï¼‰
        """
        import time
        current_time = time.time()
        cleaned_count = 0
        
        try:
            for file in self.temp_dir.iterdir():
                if file.is_file():
                    file_age_hours = (current_time - file.stat().st_mtime) / 3600
                    if file_age_hours > max_age_hours:
                        try:
                            file.unlink()
                            cleaned_count += 1
                        except Exception as e:
                            logger.warning(f"æ¸…ç†æ–‡ä»¶å¤±è´¥: {file}, é”™è¯¯: {e}")
            
            if cleaned_count > 0:
                logger.info(f"ğŸ§¹ æ¸…ç†äº† {cleaned_count} ä¸ªä¸´æ—¶æ–‡ä»¶")
                
        except Exception as e:
            logger.error(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å‡ºé”™: {e}")